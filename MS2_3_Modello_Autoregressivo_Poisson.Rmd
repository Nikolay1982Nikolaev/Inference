---
title: "Modello autoregressivo di Poisson"
author: "NikolayNikolaev"
date: '`r Sys.Date()`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## modelli lineari generalizzati per dati di conteggio:
Si consideri una variabile risposta Y e un insieme di variabili esplicative, il
modello lineare generalizzato permette di assumere una distribuzione diversa
dalla distribuzione normale per Y e di modellizzare funzioni non lineari per
la media. Nel caso dei modelli lineari generalizzati per dati di conteggio, il
modello assume per la variabile risposta una distribuzione di Poisson o una
distribuzione Binomiale Negativa.
Il modello presenta tre componenti:

- le variabile risposta e le n-osserivazioni campionarie $y_1,...y_n$ sono assunte come realizzazioni

- le variabile esplicative: sono le p-covariate con le quali si intende spiegare la variabilita della risposta e si considera un predittore lineare del tipo $\beta_0 + \beta_1.x_{i1}+ ... + \beta_p.x_{ip}$

- la dunzione legame- LINK: si tratta di una funzione g che viene applicata al valore attesso condizionato della reisposta date le covriate:
$$g(\mu_i) = \beta_0 + \beta_1.x_{i1}+ ... + \beta_p.x_{ip}$$

per i=1...n

Nel caso in modelizzare i conteggi la distribuzione di riferimento e' quella di Poisson , e la funzione log e' la funzione legame:

$$\log{\mu_i} = \beta_0 + \beta_1.x_{i1}+ ... + \beta_p.x_{ip}$$
ed il modello lineare generalizzato e' chiamato modello log-lineare di Poisson.

Se invece della Poisson si assume la distribuzione Binomiale Negativa
per permettere l'overdispersion il modello e' detto modello log-lineare basato
sulla distribuzione Binomiale Negativa.

La scelta del modello che comprende un insieme ottimale di variabili esplicative
viene efettuata generalmente utilizzando i criteri d'informazione.

Se
la stima del modello avviene con il principio di massima verosimiglianza la
log-verosimiglianza del modello cresce aumentando il numero dei parametri
pertanto i criteri d'informazione penalizzano la log-verosimiglianza per il
numero dei parametri.

Con questi criteri il modello viene scelto in base al
valore minimo dell'indice d'informazione quando si confrontano modelli con
un numero di parametri diversi.

### Bayesian Information Criterion (BIC)

$$ BIC_k = -2 \hat{l_k} (\theta) + par_k.\log{n}  $$
- $\hat{l_k}$  - l valore della log-verosimiglianza a convergenza dell'algoritmo
di stima con un numero di parametri pari a k.

- $par_k$ - parametri del modello

La log-verosimiglianza
viene pertanto penalizzata per il numero dei parametri del modello 
tenendo conto del logaritmo della numerosita (n) delle osservazioni.


### Criterio di Akaike - AIC

$$ AIC_k = -2 \hat{l_k} (\theta) + 2.par_k$$
e rispetto al BIC non considera la numerosita complessiva.




############################################


# Modello autoregressivo di Poisson non omogeneo

Alcune volte e opportuno ipotizzare che il tasso degli arrivi degli eventi che il
processo di Poisson conta non sia costante nel tempo. Pertanto si considera
un processo di Poisson con tasso non costante.

L'utilizzo del modelli di Poisson permette anche di tenere conto in
modo adeguato di queste irregolarita creando una sorta di eetto smoothing
o lisciamento nei dati.


- modello: ogni variabile $Y_T$ che rappresenta i conteggi giornalieri segua una distribuzione di Poisson con specifico parametro e quindi valore attesso $\lambda_t$.

Si assume che $\lambda_t$ soddisfi la seguente:
$$  \log{\lambda_t} = \beta_0 + t.\beta_1 + t^2.\beta_2$$
che corrisponde all'equazione di una parabola che avra una concavita rivolta
verso il basso quando il coeciente $\beta_2$ e' negativo.

I parametri si possono interpretaare onsiderando che:

$$ \lambda_t = exp(\beta_0) exp(t.\beta_1) exp(t^2.\beta_2)$$

I parametri dei modelli presentati in precedenza, vengono prevalentemente
stimati con il metodo della massima verosimiglianza. Per il modello iniziale
basato sul predittore lineare generale senza componente autoregressiva, la
funzione di verosimiglianza puo essere formulata come segue


$$ l(\theta) = \prod_{t=1}^T p(y_t, \lambda_t) $$
- $\theta$ il vettore contenente tutti i parametri del modello 
- $p(y_t, \lambda_t)$ e' calcolata in base alla distribuzione di Poisson non omogenea con parametro $\lambda_t$  formulato come nell'equazione 
$ \lambda_t = exp(\beta_0) exp(t.\beta_1) exp(t^2.\beta_2)$


#################################################

## Analisi della serie storica dei conteggi riferiti a COVID-19

Nel presente esempio (tratto da Bartolucci e Pennoni, 2020) si stima un modello di Poisson
non omogeneo nel tempo considerando la serie dei conteggi dei casi di pazienti affetti da
COVID-19.
I dati sono quelli forniti giornalmente a livello ufficiale dal Dipartimento della Protezione
Civile sullâ€™andamento del COVID-19 in Italia.
La serie inizia con i conteggi del giorno 24 Febbraio 2020 (primo giorno di rilevazione) e
viene incrementata ogni giorno.
Nel seguente esempio si considerano i dati riferiti al periodo temporale piÃ¹ recente dal 1
Agosto fino al 20 Ottobre 2022.
In particolare si seleziona la serie storica dei conteggi di interesse e si stima il modello di
Poisson non omogeneo con un trend temporale lineare, quadratico e log lineare inserendo anche
una componente autoregressiva del primo ordine (si vedano le dispense di teoria) espresso
come segue:

$$\log{\lambda_t(y_{(t-1)})}=\beta_0 +t.\beta_1 + (\frac{t^2}{100}).\beta_2 + \log{(t)}.\beta_3 + z_{(t-1)}.\rho  $$

- dove$\tho$ e' il coefficiente autoregressivo.

I dati sono di libero accesso nella piattaforma GITHUB e con la seguente sintassi si importano
nel workspace direttamente dal repository e si selezionano alcune delle categorie disponibili.
Si noti che con il seguente chunck prima si importa il dataframe con i conteggi di tutte le
date disponibili fino al giorno corrente e poi con la funzione subset si seleziona il perido di
interesse.
```{r}
repository <- "https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/"
overall.dataset <- "dati-andamento-nazionale/dpc-covid19-ita-andamento-nazionale.csv"
overall.filename<-paste(repository,overall.dataset,sep="")
Italy<-read.csv(overall.filename)

names(Italy)

library(dplyr)

dataItaly<- Italy %>%
select(data,
dimessi_guariti,
isolamento_domiciliare,
ricoverati_con_sintomi,
terapia_intensiva,deceduti)
mydate <- as.Date(as.POSIXct(dataItaly$data, format="%Y-%m-%dT %H:%M:%S"))
df <-data.frame(mydate,dataItaly$isolamento_domiciliare)
colnames(df)<-c("date", "Isolati")
df1 <- subset(df, date >= as.Date('2022-08-01') & date <= as.Date('2022-10-20'))
```

Si nota che vi sono 24 campi disponibili per i dati nazionali.
Il dataframe denominato df Ã¨ stato creato considerando solo la data e la serie dei conteggi
che si intende usare: ovvero ad esempio i pazienti posti in isolamento domiciliare.
Si vede che i giorni di rilevazione vanno dal 24 febbraio al 20 ottobre 2020
```{r}
min(df$date)
max(df$date)
```
Il data frame df1 invece considera lâ€™ultimo periodo.
Lâ€™utilizzo del modelli di Poisson permette anche di tenere conto in modo adeguato delle irregolaritÃ 
presenti nei dati, e pertanto i valori interpolati creano una sorta di effetto smoothing
o lisciamento ai dati osservati.

```{r}
require(skimr)
skimr::skim_without_charts(df1$Isolati)
```

Si rappresenta graficamente la serie osservata

```{r}
n<-length(df1$Isolati)
ma<-max(df1$Isolati)
mi<-min(df1$Isolati)
ytick<-c(mi,409247,ma)
xtick<-c(1,11, 21, 31, 41, 51, 61, 71, 81)
plot(df1$Isolati,
     ylab=expression("Isolamento ("*italic(y[t])*")"),
     xlab=expression("Giorni ("*italic(t)*")"),
     yaxt="n",
     xaxt="n",
     xlim =c(1,n+5),
     ylim = c(0,ma+10),
     lwd = 0.5,
     lty = 1,
     col ="black" )
axis(side=2, 
     at=ytick, 
     labels = FALSE,
     cex.lab = 0.5, 
     padj = 2,
     tck=-0.009)
text(par("usr")[1], 
     ytick,
     labels = ytick, 
     srt = 45,
     pos = 2, 
     xpd = TRUE, 
     cex.lab = 0.1)
axis(side=1, 
     at=xtick,
     labels = FALSE, 
     cex=0.1,
     tck=-0.009)
text(x=xtick,
     par("usr")[3],
     labels = xtick,
     cex.lab = 0.5,
     pos = 1, 
     xpd = TRUE)
```

Il modello di Poisson non omogeneo si stima definendo le covariate riferite al tempo e
menzionate in precedenza: il trend lineare, quadratico e log-lineare nel modo seguente

```{r}
regressors1Italy <- cbind(linearTrend=seq(along=df1$Isolati),
                          quadTrend = seq(along=df1$Isolati)^2/100,
                          linlogTrend = log(seq(along=df1$Isolati)))
head(regressors1Italy)
```
Per stimare il modello con il metodo della massima versosimiglianza si utilizza la funzione
tscount::tsglm della libreria (da installare, tscount proposta da Liboschik et al., 2020)
(Analysis of Count Time Series)

Si noti che la prima opzione del chunk seguente serve per rimuovere la notazione scientifica
che alcune volte puÃ² essere stampata in output.
```{r}
options(scipen = 100)
require(tscount)
M3Italy <- tsglm(ts=df1$Isolati,
  link = "log",
  model=list(past_obs=1),
  xreg=regressors1Italy,
  distr = "poisson")
```
Come giÃ  sperimentato per la funzione glm occorre fornire:
- i dati osservati come serie univariata dei conteggi,
- la funzione link per il modello log-lineare per ðœ†ð‘¡,
- definire lâ€™ordine del ritardi con past_obs,
- la matrice delle covariate temporali xreg e la distribuzione di riferimento.

```{r}
summary(M3Italy)
```
Viene fornito in output il valore massimo della funzione di log-verosimiglianza a convergenza,
il numero dei parametri stimati con il modello, ed i valori degli indici di selezione BIC (criterio
dâ€™informazione Bayesiano), AIC (criterio di Akaike) e una sua versione aggiustata definita
QIC (quasi information criterion).

Dalla sintesi dei risultati delle stime del modello notiamo che lâ€™intercetta del modello ha un
valore positivo e corrisponde al valore del logaritmo di lambda quando tutte le covariate
hanno valore 0.

Le stime dei coefficienti di regressione sono fornite insieme allâ€™intervallo di confidenza
calcolato al livello del 95% utilizzando il metodo asintotico (basato sullâ€™approssimazione
dello stimatore alla distribuzione Normale).

Si noti che tutti i coefficienti sono positivi tranne i due coefficienti riferito al trend quadratico
e al trend log-lineare nel tempo.

Si noti che Ã¨ di particolare interesse confrontare i valori osservati con i valori interpolati.
Eâ€™ inoltre di interesse fare delle previsioni: calcolare i conteggi attesi in base al modello
stimato per gli isolati di oggi (20 ottobre 2022) e per quelli dei prossimi 4/5 giorni.

Come per la funzione glm i valori previsti si ottengono con la funzione predict.

Si noti che la funzione tsglm::predict implementa il method="bootstrap" ovvero la distribuzione
dei valori previsti Ã¨ approssimata con il bootstrap parametrico basato di default
su B = 1000 traiettorie simulate dal modello stimato. Si noti che in questo modo si associa
alla stima puntuale della previsione un intervallo definito intervallo predittivo calcolato con
una confidenza di 0.95.

```{r}
go <- 5
TT <- length(df1$date)
P3Italy <-predict(M3Italy,
                  newxreg = data.frame(linearTrend = ((TT+1):(TT+go)),
                                       quadTrend = ((TT+1):(TT+go))^2/100,
                                       linlogTrend = log((TT+1):(TT+go))),
                  n.ahead=go,
                  method="bootstrap" )
```
La seguente tabella riporta i valori previsti degli isolati, insieme ai limiti dellâ€™intervallo
predittivo al 95%, per oggi e per i prossimi 4 giorni
```{r}
pred<-data.frame(cbind(P3Italy$pred,P3Italy$interval))
colnames(pred)<-c("previsti", "PIinf", "PIsup")
pred
```
Si nota che il numero degli isolati atteso per domani Ã¨ di 514103 ed il trend Ã¨ quello che iil
numero decresca nei giorni successivi.

Si nota che le ampiezze degli intervalli sono modeste e che queste crescono al crescere del
giorno previsto. CiÃ² denota, come ci si aspetta, un aumento dellâ€™incertezza delle previsioni
via via che ci si allontana dallâ€™ultima data di osservazione.

Le seguente figura mostra i conteggi osservati dei pazienti isolati per tutto il periodo considerato
insieme ai valori interpolati con il modello stimato a cui vengono aggiunti i valori
previsti per il periodo temporale riportato che sono visualizzati dopo la retta grigia che
indica il giorno di ieri

```{r}
ytick<-c(mi,409247,ma)
xtick<-c(1,11, 21, 31, 41, 51, 61, 71, 81)
plot(df1$Isolati,
     ylab=expression("Isolamento ("*italic(y[t])*")"),
     xlab=expression("Giorni ("*italic(t)*")"),
     yaxt="n",
     xaxt="n",
     xlim =c(1,n+5),
     ylim = c(0,ma),
     lwd = 0.5,
     lty = 1,
     col ="black" )
abline(v=240, col = "gray")
axis(side=2, 
     at=ytick, 
     labels = FALSE,
     cex.lab = 0.5, 
     padj = 2,
     tck=-0.009)
text(par("usr")[1],
     ytick,
     labels = ytick, 
     srt = 45,
     pos = 2, 
     xpd = TRUE, 
     cex.lab = 0.1)
axis(side=1, 
     at=xtick,
     labels = FALSE, 
     cex=0.1,
     tck=-0.009)
text(x=xtick,
     par("usr")[3],
     labels = xtick,
     cex.lab = 0.5,
     pos = 1, 
     xpd = TRUE)
lines(c(M3Italy$fitted.values,
     pred$previsti),
     lwd=3, 
     col = 3, 
     lty = 4)
legend("bottomleft",
       pch = c(20,NA,NA,NA,NA),
       lty = c(NA,2),
       legend = c("osservati", "interpolati e previsti"),
       col = c("black", "green"),
       bty = "n",
       x.intersp = 0.1,
       cex= 0.6, 
       pt.cex = .5,
       xpd = TRUE,
       text.width = 0.0001)
       
```

###################################################


## Modello autoregressivo con distribuzione Binomiale Negativa


il modello
diventa tale che include in modo moltiplicativo un termine casuale specico
del tempo ed e il seguente:

$$\lambda_t' = \lambda_t exp(\epsilon_t)  $$
- $\lambda_t;$ - il valore atteso condizionato del conteggio al tempo t, cioe $Y_t$

Il termine casuale rappresenta un possibile errore di specicazione
del modello dovuto a variabili esplicative non osservate e pertanto omesse dal
modello e permette, appunto, di tenere conto della eterogeneita non osserva-
ta.

Generalmente si assume che $\nu_t = exp(\epsilon_t)$ isa indipendente dalle covariate e abbia una particolare distribuzione con valore atteso pari a 1 e varianza constane $\sigma^2$ , che ovviamente puo essere solo postitiva. 

Di conseguenza , il valore atteso e la variaznza di $Y_t$ sono pari a :
$$\lambda_t \epsilon \lambda_t(1 + \lambda_t /sigma^2)$$

rispettivamente. Si noti che la varianza puo essere superiore al valore atteso
(overdispersion). La stima dei parametri del modello viene efettuata attraverso
il metodo della quasi massima verosimiglianza nell'ambito del quale il
parametro di overdispersion viene stimato sulla base delle stime preliminari
dei coefcienti di regressione.



###################################################
Nel presente esempio si consida un modello basato sulla distribuzione Binomiale Negativa
per la serie dei conteggi dei casi di pazienti affetti da COVID-19.
Nellâ€™ applicazione precedente la stima del parametro autoregressivo Ã¨ diversa da zero $\hat{\rho}=0.99$ beta1.

Il modello basato sulla distribuzione Binomiale Negativa include il parametro di overdispersion
in modo che la il valore atteso dei conteggi Ã¨ $\lambda_t$ mentra la varianza e' diversa dal valore atteso
e risulta $\hat{\lambda}.(1+\hat{\lambda}.\hat{\sigma^2})$
```{r}
options(scipen = 100)
require(tscount)
M4Italy <- tsglm(ts=df1$Isolati,
                 link = "log",
                 model=list(past_obs=1),
                 xreg=regressors1Italy,
                 distr = "nbinom")
```

ovvero specificando la distribuzione Binomiale Negativa con distr = "nbinom".
In questo caso il modello presenta un parametro aggiuntivo riferito a $\sigma^2$
```{r}
summary(M4Italy)
```

Dalla sintesi dei risultati del modello notiamo che la stima del parametro $\sigma^2$ Ã¨ 0.00375 che
risulta pertanto postiva indicando overdispersion.
Per calcolare lâ€™errore standard occorre applicare il bootstrap che verrÃ  introdotto nei giorni
seguenti.

I valori previsti per i cinque giorni successivi (dal 19 al 23 ottobre) con questo modello si
ottengono con la funzione predict ed in modo analogo a quanto mostrato per il modello
stimato con la distribuzione di Poisson possiamo calcolarle dopo aver specificato le covariate
temporali.

```{r}
go <- 5
TT <- length(df1$date)
P4Italy <-predict(M4Italy,
newxreg = data.frame(linearTrend = ((TT+1):(TT+go)),
quadTrend = ((TT+1):(TT+go))^2/100,
linlogTrend = log((TT+1):(TT+go))),
n.ahead=go,
method="bootstrap" )
pred<-cbind(P4Italy$pred,P4Italy$interval)
colnames(pred)<-c("previsti", "PIinf", "PIsup")
pred
```

Eâ€™ interessante notare che il valore puntuale del conteggio previsto Ã¨ simile a quello ottenuto
con il modello di Poisson tuttavia in base allâ€™overdispersion lâ€™itervallo predittivo calcolato
con una fiducia di 0.95 ha maggiore ampiezza.
I conteggi osservati dei pazienti isolati per tutto il periodo considerato insieme ai valori
interpolati con il modello stimato e i valori previsti possono essere rappresentati graficamente

```{r}
plot(df1$Isolati, 
     lwd = 0.5,
     lty = 1,
     col ="black",
     xlab = "Giorni",
     ylab= "Conteggio Isolati",
     ylim = c(mi,ma+2), 
     xlim = c(0,n+5))
     abline(v=81, 
     col = "gray")
lines(c(M4Italy$fitted.values, P4Italy$pred),
     lwd=2, 
     col = 2, 
     lty = 2)
     legend("bottomleft",
            lty = c(1,2),
            legend = c("osservati", "interpolati e previsti"),
            col = c("black", "red"),
     bty = "n",
     x.intersp = 0.1,
     cex= 0.6, 
     pt.cex = .5,
     xpd = TRUE,
     text.width = 0.0001)
```
## Valutazione della prevalenza nel tempo
Considerando la popolazione complessiva Ã¨ possibile stimare in base al modello la prevalenza
che misura la proporzione dellâ€™evento (Isolamento nel presente caso) in una popolazione in
un dato momento.

Per lâ€™Italia la numeroritÃ  della popolazione totale Ã¨ reperibile dal sito dellâ€™Istituto Nazionale
di Statistica che riporta che popolazione residente al 1 Gennario 2020 Ã¨ di 60317000 unitÃ 
https://www.istat.it/it/archivio/238447

Utilizzando questâ€™informazione Ã¨ possibile calcolare la prevalenza dividendo i valori per
questo numero (e moltiplicando per mille)

```{r}
prev<-c(M4Italy$fitted.values,P4Italy$pred)/60317000
prev<-prev*1000
```

E verificare in base al modello stimato come questa si Ã¨ modificata nel tempo ad esempio
con il seguente grafico

```{r}
plot(prev, type = "l",
     xlab = "Giorni",
     ylim = c(0,20),
     lwd=2,
     col = "blue", 
     ylab = "(prevalenza isolati)*1000")
```

che permette di evidenziare la prevalenza di casi ogni 1000 abitanti. In questo modo Ã¨
possibile anche fare confronti tra diversi paesi.





