---
title: "Generazione di determinazioni da variabili casuali"
author: "NikolayNikolaev"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Generare delle realizzazioni da variabili casuali signica produrre al calcolatore
valori che provengono da una determinata distribuzione di probabilita
(densita) di una variabile casuale discreta, continua, unidimensionale o multidimensionale.




# Generazione di determinazioni da variabili casuali

Le funzioni implementate in R utilizzano dei suffissi per definire le seguenti quantit√†:
- d per calcolare la densit√† in un punto;
- p per calcolare la funzione di ripartizione in un punto
- q per calcolare un quantile
- r per generare pseudo-determinazioni dalla distribuzione

Le funzioni di :
-  Exponential: nome exp;
-  Gamma: nome gamma;
-  Student t: nome t
- Normale: nome norm

Per la distribuzione Normale standard nella libreria stats si ha:
- dnorm
- pnorm
- qnorm
- rnorm

## Generazione di pseudo-derminazioni dalla v.c. di Gauss

- indicata $X =N(\mu, \sigma^2)$
- parametri $\mu \in R$ and $\siga \in R^+$
- particolarmente utile dato che il teorema del limite centrale stabilisce, con relative non troppo stringenti assunzioni, che la somma(convuluzione) di molte variabili casuali indipendenti e identicamnte distribuite, ha una distribuzione normale, indipendentemente della distribuzione delle singole variabii casuali.

Funzione di densita:

$$f(X) = \frac{1}{\sigma.\sqrt{2.\pi}} exp(- \frac{1}{2.\sogma^2} (x-\mu)^2)$$

- $-\infty < x < \infty $
- $\mu, \sigma > 0, \pi=3.14...$

Proprieta:
1. sia $Z=N(0,1) => Z.\sigma+\mu=X$
2. E' sufficente avere un metodo che generi determinazioni dalla distribuzione Normale Standard per ottenere mediante semplice trasformazioni lineare $Z.\simga + \mu = X$, determinazioni da qualunque variabile casuale appartenente alla famiglia $N(\mu, \sigma^2)$
3. Data n-variabile casuale Normali indipendenti
$$X_i = N(\mu_i, \sigma_i^2)$$
- con i =1...n la variabile casuale:
$$Y = \sum_{i=1}^n X_i$$

ha la sequente distribuzione:
$$Y=N(\sum_{i=1}^n \mu_i; \sum_{i=1}^n \sigma^2)$$
Una variabile casuale continua Z assume una distribuzione normale standard se la funzione di densita e':

$$f(x) = \frac{1}{\sqrt{2\pi}} exp(-\frac{1}{2} z^2)$$
E si scrive: Z = N(0,1)

- $\frac{1}{\sqrt{2\pi}}$ - constante di normalizzazione 

- La funione di ripartizione della variabile casuale normale standard rappresenta l'area sottostante la funzione di densita:

$$\Phi(z) = \int_{-\infty}^z \frac{1}{\sqrt{2\pi}} exp(-\frac{1}{2} t^2) dt$$

si deduce:
- la simmetria della funzione di densita
- la simetria dell'area presente sulle code della distribuzione $\Phi(z) = 1-\Phi(-z)$$
- la simetria di Z and -Z





Si generano 10 realizzazioni dalla variabile casuale di Gauss con media zero e varianza 1

```{r}
rnorm(10, 0, 1)
```


Si generano 1000 realizzazioni e si disegna distribuzione empirica

```{r}
n <- 1000
set.seed(27732)
Z <- rnorm(1000)
mean(Z); sd(Z)
hist(Z, 
     breaks = 30,
     freq=FALSE,
     main="Z = N(0,1)",
     col ="blue",
     ylab="Densit√†",
     ylim =c(0,0.6))
```
Per generare 10 realizzazioni da una distribuzione di Gauss tale che $X$ ~ $N(4, 16)$ si puo applicare la trasformazione $(Z. \sigma + \mu)$
dove $Z$ rappresentano i generati dalla Normale Standard oppure utilizzare la dunzione media e **deviazione standard**.
```{r}
rnorm(10,mean = 4, sd = 4 )
```


## Generazione dalla variabile casuale Esponenziale

La variabile casuale esponeziale ha una distribuzione flessibile e simmetrica rispetto ai valori postivi del supporto

- eventi temporali

Sia X il tempo di attesa fino al primo evento allora $X=Exp(\lambda)$ quando:
$$
c_i =
\begin{cases} 
\lambda exp(-\lambda x) & x>= 0 \\ 
0 & altrove 
\end{cases}
$$
- con $x>=0, \lambda >0$
- $\frac{1}{\lambda}$ tempo medi  di attesa per l'evento nell uniata di tempo

- quanto piu elevato e' il tasso di occorenza #\lambda$ dell'evento tanto minore sara il tempo di attesa

Funzione di ripartizione:
$$ p(X=< x) = F_X(x) = \int_0^x e^{-t} dt = -e^{-t} |_0^2 = 1 - e^{-x\lambda}$$

- assenza di memeoria
- probabilita di aspetare ancora altri s miniti : $P(t+s) = P(s)$ e' ugiale a quella di dover aspettare per s minuti complessivi.

- la somma di n-variabili casuali indipendenti con distribuzione esponenziale e tutti aventi lo stesso parametro $\lambda$ allora varaibile casuale
$Y = X+_1+X_2...+X_n$ ha una distribuzione Gamma di parametri $(n, \lambda)$

- la statistica d'ordine minimo di una serie di variabili casuali espoenenziali indipendenti $X_{(1)} = min (X_1...X_n)$ con parametri $(\lambda_1,...,\lambda_n)$ ha ancora un distribuzione esponenziale $X_{(1)} = Esp(\sum_i^n \lambda_i)$







Nel seguente chuck si crea una griglia di 101 valori e si calcola la densit√† della v.c. esponenziale
con $\lambda = 1$ nei puti generati.
```{r}
x<-seq(0,5,length=101)
head(x)
h<-dexp(x,rate = 1)
head(h)
```

La media della v.c. e' 1 e la varianza e' 1.
Nel seguente grafico si rappresenta la funzione di densita.
```{r}
plot(x,h,
     type="l", 
     col = "blue",
     lwd = 3, 
     ylim = c(0,2),
     xlab = "Tempo di sopravvivenza", 
     ylab = "Densit√†")
```

Si generano 1000 volte delle realizzazioni da v.c. esponenziali indipendenti con $\lambda=1$

Nel seguente si fissa una numerosit√† campionaria, si generano 3 realizzazioni dalla v.c. esponenziale
di riferimento, si calcola la media aritmetica delle tre realizzazioni e si salvano
nell‚Äôoggetto $m$
```{r}
n <- 3
m <- rep(0, 1000)
for(i in 1:1000){
  m[i]<-mean(rexp(n, rate=1))
  }
head(m)
```
Si sovrappone l‚Äôistogramma dei valori generati alla curva disegnata in precedenza

```{r}
plot(x,
     h,
     type="l", 
     col = "blue",
     lwd = 3, 
     ylim = c(0,2),
     xlab = "Tempo di sopravvivenza", 
     ylab = "Densit√†")
hist(m, 
     prob= T, 
     add=T, 
     col = rgb(0,0,1,1/4), 
     breaks = 25)
legend(3, 1.5, 
       c("teorica", "realizzazioni n = 3"),
       col = c("blue", "lightblue"),
       lty = c(1,1),
       lwd = c(2,1),
       cex = 0.6)
```
Per il teorema del limite centrale sappiamo che c‚Äô√® la covergenza alla distribuzione
Normale.

#####################################################################################################

## V.c Gamma
- generalizzazione di esponenzialie

- $\alpha >0$ - di forma
- $\beta > 0 $ - con $\frac{1}{\beta}$ di scala

$$f(x) = 
\begin{cases} 
\frac{\beta^{\alpha}}{\Gamma(\alpha)}.x^{\alpha-1} exp(-\beta x) & x > 0 \\ 
0 & altrove 
\end{cases}
$$
Funzione Gamma: $|gamma(\alpha) = \int_0^{\infty} x^{\alpha - 1} exp^{-z} dz$ 

Funzione Chiquadrato e un caso speciale di gamma

- modello per fenomeni continui e positivi (illimitati)



#####################################################################################################

## Generazione di pseudo-derminazioni dalla v.c. Beta

- $\alpha>0, \beta$

$$f(x) = 
\begin{cases} 
\frac{\beta^{\alpha}}{B(\alpha, \beta)}.x^{\alpha-1} (1-x)^{\beta-1} & 0 < x < 1 \\ 
0 & altrove 
\end{cases}
$$
dove 
$$B(\alpha, \beta) = \int_0^1 x^{\alpha-1} (1-x)^{\beta-1} = \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)}$$

- fenomeni continui che assumono valori in un intervallo limitato, ricondicibile, mediante opportune trasformazioni all'intervllo (0,1)

- durata respiratoria









La distribuzione $Beta(\alpha, \beta)$ e' definita per valori di $0<x< 1$ e per $\alpha, \beta > 0$

Si generano 1000 osservazioni dalla distribuzione beta standard con $\alpha=1$ and $\beta=1$. Si tratta della distribuzione uniforme in $(0,1)$

```{r}
n<-1000
set.seed(27732)
alpha <- 1
beta<- 1
B <- rbeta(n,alpha,beta)
summary(B)
```
Si disegna l‚Äôistogramma
```{r}
hist(B,
  breaks = 50,
  freq=FALSE,
  main="Beta (1,1)",
  col ="grey",
  ylab="Densit√†"
)
curve(dbeta(x,1,1),
  col = "red",
  add = TRUE )
```
Si nota dalle statistiche descrittive che i numeri possono essere assunte come determinazioni
pseudo-casuali.
- si ottengono ancora 1000 realizzazioni ponendo $\alpha=0.5$ and $\beta=0.7$ e si sovrappone la **curva teorica** generata attraverso la funzione **dbeta**.

```{r}
alpha <- 0.5
beta  <- 0.7
B1    <- rbeta(n,alpha,beta)
#
hist(B1,
  breaks = 50,
  freq=FALSE,
  main="Beta (0.5,0.7)",
  col ="grey",
  ylab="Densit√†",
  ylim=c(0,6)
)
#
curve(dbeta(x,alpha,beta),
    col = "red",
    add = TRUE, 
    lwd=2 )
legend(0.6,4, c("realizzazioni n = 1000", "distr. teorica"),
    col = c("grey", "red"),
    lty = c(1,1),
    lwd = c(1,2),
    cex = 0.4)
```


## V.c Bernoulli:

- casuale discrete
- fenomeni dicotomici (0,1)
- $p \in (0,1)$

$$f(x) = P(X=x)=
\begin{cases} 
p^x (1-p)^{1-x} & x= 0,1 \\ 
0 & altrove 
\end{cases}
$$
- indicato con $U$ - la variabile casuale Uniforme(0,1) :$P(0<U<p) = p = P(X=1) and P(p<U<1) = 1-p = P(X=0)



## Generazione di pseudo-derminazioni dalla v.c. Binomiale

- modellare il numero di successi su $n$ prove indipendenti, cisacuna con probabilita di successo costantemente pari a $p$

- parametri $n \in N$ and $p \in (0,1)$ 

Funzione di probabilita:


$$f(x) = P(X=x)=
\begin{cases} 
\binom{n}{x} p^x (1-p)^{n-x} & x= 0,1 ..n\\ 
0 & altrove 
\end{cases}
$$

Infatti con n-prove indipendenti la proabibilita di una certa sequenza e' l'intersezione di n-eventi indipendenti e pertanto ad essempio la sequenza seguente $(1,1,0,0...0)$ ha la seguente probabilita:
$$P(X_1=1) P(X_2=1)P(X_3=0) ...P(X_n=0) = p^2(1-p)^{n-2}$$

Si nota che la proabilita e' la stessaindipendentemente dal momento in cui si verficano i due successi e pertanti si scrive:

$$P(X=2) = \binom{n}{2} P^2(1-p)^{n-2}$$


Ad esempio, si utilizza per modellizzare la proporzione di soggetti con una
certa malattia quando la numerosita della popolazione e ampia (N >5000).







Si genera una sequenza di valori interi da 0 a 12 (ùëõ = 2), si fissa la probabilit√† di successo
pari a 0.3 e si determinano le probabilit√† corrispondenti ai valori di x, si rappresentano
graficamente

```{r}
y= seq(0, 12, 1); y
dy <- dbinom(y,12,0.2); dy

plot(y, dy, type="h")
```
Per generare dei numeri dalla distribuzione Binomiale si utilizza **rbinom**. Con il seguente
codice si genera una realizzazione del risultato di un esperimento un cui la probabilit√†
dell‚Äôevento successo √® 0.2 e si ripete l‚Äôesperimento per 8 volte
```{r}
set.seed(123)
rbinom(1, 8, 0.20)
```
ovvero su 8 prove si riscontra solo un successo.

Il seguente codice permette di simulare 8 realizzazioni di un esperimento in cui la probabilit√†
di successo √® sempre 0.2
```{r}
rbinom(8, 1, 0.20)
```
il risultato √® che si verifica un succeso alla terza, quarta e settima prova.









## Generazione di pseudo-derminazioni dalla v.c. di Poisson
Per una variabile
casuale discreta, assume un'innita numerabile di valori. Viene utilizzata per
modellizzare dei conteggi di occorrenze di eventi che avvengono casualmente
nel tempo se:
‚Ä¢ i conteggi degli eventi che avvengono in periodi dierenti sono indipendenti;
‚Ä¢ risulta impossibile che due eventi si verichino simultaneamente;
‚Ä¢ il tasso di occorrenza degli eventi risulta costante.

- parametro $\lambda >0$ costente, in questo cso la distribuzione e' detta omogenea.

- fenomeni che si presentano casualmente nello spazio o nel tempo sotto le seguenti condizioni:
1. i conteggi degli eventi che avvengono
in periodi disgiunti sono indipendenti
2. e impossibile che due o piu eventi si
realizzino simultaneamente
3. tasso di occorrenza e costante

Questa distribuzione e legata alla cosiddetta legge degli eventi rari per alcune
ragioni probabilistiche,

La somma di variabili casuali esponenziali indipendenti con stesso tasso $\lambda$ origina un processo Poisson di omogeneo a tasso $\lambda>0$.

Se X rappresenta il numero di eventi che accadono in un intervallo di tempo oppure in una distanza unitaria sotto l'ipotessi che gli eventi siano indipendenti, la probabilita
di osservare un certo numero di eventi nell'intervallo di tempo dipende solo
dalla lunghezza dell'intervallo e non da dove inizia l'intervallo di tempo, e $\lambda$
rappresenta il numero medio di eventi nell'intervallo di lunghezza uniaria.


$$f(x) = P(X=x)=
\begin{cases} 
\frac{\lambda^x}{x!} exp(-\lambda) & x= 0,1 ..n\\ 
0 & altrove 
\end{cases}
$$

modello- il numero di nascite naturali
che avvengono un grande ospedale. Si applica anche come approssimazione
della distribuzione binomiale quando n e grande e p piuttosto piccolo, con $\mu=n.p$

- $E[X] = Var[X] = \lambda$

Pertanto al crescere della media cresce
anche la variabilita della variabile casuale.

Ad esempio nell'analisi di Y numero di deceduti al giorno in incidenti
automobilistici in Italia, la probabilita p di questo evento in un giorno
varia in base alle capacita delle persone che si mettono alla guida ed in base
al numero di ore spese in automobile. Per cui la distribuzione eettiva della
variabile casuale che costituisce il meccanismo generatore dei dati avra sicuramente
maggiore variabilita della variabile casuale di Poisson. Questo fatto
e detto overdispersion.





Si genera una sequenza di valori tra 30 e 120 con incremento di 1.
```{r}
y = seq(30, 120, 3)
plot(y, dpois(y, 80), type='h')
```

Si rappresenta la densit√† di Poisson fissando la media a 80
Per generare 100 realizzazioni dalla distribuzione di Poisson con parametro $\lambda=22$ si utilizza.
```{r}
set.seed(163)
y <- rpois(100, 22); y
mean(y)

var(y)
```
































